## The following is the R codes for part of the simulations presented in section 3.2. The codes contain the scheme to generate the simulated dataset.  By running the codes, we can get the 
## results for penalized spline estimators and regression spline estimators in Table 3 under sample size 100.


#set the diretory
#setwd("H:/project1/fuwuqi")
#remove all the subjects
rm(list=ls())
#library package
library(Matrix)      
library(fda)         
library(splines)
library(quadprog)
library(MASS)

## Setting1         
f.lambda<-function(x){0.1*x*x+2}
f.beta <- function(x){sin(0.1*pi*(x-5))+1}

start<-Sys.time()



#####generate the simulated dataset

data.gen<-function(nsub,                                #---Sample size
                   max.obs,                             #---Maximal number of observation for each individual 
                   irate,                               #---Rate for interarrival time
                   len)                                 #---Length of study
{
  Z1 <- round(runif(nsub,0,1),3)                         #define covariate Z with time-varying effect 
  X1 <- round(runif(nsub,0,1),3)                         #define covariate X1 with time-constant effect 
  X2 <- rbinom(nsub,size=1,prob=0.5)               #define covariate X2 with time-constant effect
  
  alpha1 <-  -0.5                                     
  alpha2 <-  1.5                                      #define true alpha1,2
  
#---To create a database starting from the first subject
  
  NumObs <- rep(nsub,0)      
  
  rexpf<-function(n,irate){
    u<-runif(n,0.01,0.99)
    x<--log(u)/irate
    return(x)
  }
  
  x<-round(rexpf(max.obs,irate),2)                    # generate observation time for the first subject
  while(x[1] >= len)                                  
    x<-round(rexpf(max.obs,irate),2)
  
  for(j in 1:max.obs){                                  
    if(sum(x[1:j])< len)
      k<-j
  }                                                    # choose the cummulative time less than the length of study
  
  indtimeObs<-cumsum(x[1:k])                           # observation time(T_(1j))
  NumObs[1]<-length(indtimeObs)                    # the number of observations for the first subject
    
  subj<-rep(1,NumObs[1])                                # identification for the first subject
  indcount <- rep(0, NumObs[1])                         
  indcount[1] <- rpois(1,f.lambda(indtimeObs[1])*exp(Z1[1]*f.beta(indtimeObs[1])+X1[1]*alpha1+X2[1]*alpha2)) #cummulative panel count when the number of observation is only one 
  
  if(NumObs[1] > 1) {
    for(j in 2:NumObs[1])
      
      indcount[j] <- indcount[j - 1] + rpois(1, (f.lambda(indtimeObs[j])*exp(Z1[1]*f.beta(indtimeObs[j])+X1[1]*alpha1+X2[1]*alpha2)-f.lambda(indtimeObs[j-1])*exp(Z1[1]*f.beta(indtimeObs[j-1])+X1[1]*alpha1+X2[1]*alpha2)))
    
  }                                                      #cummulative panel count when the number of observation is more than one
  
  timeObs <- indtimeObs                                  #define observation time  (T_(1j))
  count<- indcount                                       #define panel count (N_(1j))
  covar1<- rep(Z1[1], NumObs[1])                         #covariate1 for subject 1
  covar2<- rep(X1[1], NumObs[1])                         #covariate2 for subject 1
  covar3<- rep(X2[1], NumObs[1])                         #covariate3 for subject 1
  
  #---To expand the database by adding the subsequent observations
  for(i in 2:nsub) {
    x<-round(rexpf(max.obs,irate),2)                   #generate observation time for the ith subject               
    while(x[1] >= len)                                
      x<-round(rexpf(max.obs,irate),2)
    
    for(j in 1:max.obs){
      if(sum(x[1:j])< len)
        k<-j
    }                                                
    
    indtimeObs<-cumsum(x[1:k])                         #---Inter arrival time---
    NumObs[i]<-length(indtimeObs)                      #the number of observations for the ith subject
     
    subj <- append(subj, rep(i, NumObs[i]))               #generate identification from i to nsub
    indcount <- rep(0, NumObs[i])
    
    indcount[1] <- rpois(1, f.lambda(indtimeObs[1])*exp(Z1[i]*f.beta(indtimeObs[1])+X1[i]*alpha1+X2[i]*alpha2)) 
    
    if(NumObs[i] > 1) {
      for(j in 2:NumObs[i])
        indcount[j] <- indcount[j - 1] + rpois(1,(f.lambda(indtimeObs[j])*exp(Z1[i]*f.beta(indtimeObs[j])+X1[i]*alpha1+X2[i]*alpha2)-f.lambda(indtimeObs[j-1])*exp(Z1[i]*f.beta(indtimeObs[j-1])+X1[i]*alpha1+X2[i]*alpha2)))
                  
    }
    
    timeObs <- c(timeObs, indtimeObs)           #combine all the observation time
    count <- c(count, indcount)                 #combine all the panel count
    covar1 <- c(covar1,rep(Z1[i],NumObs[i]))    #combine all the covariate 1
    covar2 <- c(covar2,rep(X1[i],NumObs[i]))    #combine all the covariate 2
    covar3 <- c(covar3,rep(X2[i],NumObs[i]))    #combine all the covariate 3
  }#--- end of i--- 
  
  
  #----To construct a dataframe
  cbind(subj,timeObs,count,covar1,covar2,covar3)
  
}




##### Algorithm 1

projected.NR<-function(theta0,object,gradient,hessian,constraint.matrix,constraint.vector,accuracy,e,iterate_max) 
{
  theta.current <- theta0
  eigen.min <- min(eigen(-hessian(theta.current),only.values = T)$values)     
  eigen.max <- max(eigen(-hessian(theta.current),only.values = T)$values)      
  
  if(eigen.min>=0&eigen.max<=10^10)  H <-(-solve(hessian(theta.current)))  else stop("the hessian at theta0 is not positive definate")
 
  B.theta.current <- theta.current+H%*%gradient(theta.current)
  
  theta.tu <- solve.QP(2*(-(hessian(theta.current))),2*(-(hessian(theta.current)))%*%B.theta.current,constraint.matrix,constraint.vector)$solution
 
  ### line search
  x <- theta.current; y <-  theta.tu 
  if(object(y)>=object(x)+e*t(gradient(x))%*%(y-x)) theta.next <- y  else
  {
    lam <-1 ; p <- 0.5;
    while((object(y)>object(x)+(1-e)*t(gradient(x))%*%(y-x)|object(y)<object(x)+e*t(gradient(x))%*%(y-x))&(p>1e-15))       
    {
      if (object(y)>object(x)+(1-e)*t(gradient(x))%*%(y-x)) lam <- lam+p
      if(object(y)<object(x)+e*t(gradient(x))%*%(y-x))   lam <- lam-p
      y <- x+lam*(theta.tu-x); p <- p/2
    }
    theta.next <- y
  }
  
  ### iterate >=2
  if(max(abs(theta.next-theta.current))<=accuracy) list(index=1,iterate=1,theta.est=theta.next) else
  {
    
    index <- 0; iterate <- 2
    while (iterate<=iterate_max) 
    {
      eigen.min <- min(eigen(-hessian(theta.next),only.values = T)$values)      
      eigen.max <- max(eigen(-hessian(theta.next),only.values = T)$values)      
      
      if(eigen.min>=0&eigen.max<=10^10)  H <-(-solve(hessian(theta.next)))  else H <-(-solve(diag(diag(hessian(theta.current)))))
      
      B.theta.current <- theta.next+H%*%gradient(theta.next)
      if(eigen.min>=0&eigen.max<=10^10) theta.tu <- solve.QP(2*(-(hessian(theta.next))),2*(-(hessian(theta.next)))%*%B.theta.current,constraint.matrix,constraint.vector)$solution else
        theta.tu <- solve.QP(2*(-(diag(diag(hessian(theta.current))))),2*(-(diag(diag(hessian(theta.current)))))%*%B.theta.current,constraint.matrix,constraint.vector)$solution 
      theta.current <- theta.next
      
      x <- theta.current; y <-  theta.tu 
      if(object(y)>=object(x)+e*t(gradient(x))%*%(y-x)) theta.next <- y  else
      {
        lam <-1 ; p <- 0.5;
        while((object(y)>object(x)+(1-e)*t(gradient(x))%*%(y-x)|object(y)<object(x)+e*t(gradient(x))%*%(y-x))&(p>1e-15)) 

        {
          if (object(y)>object(x)+(1-e)*t(gradient(x))%*%(y-x)) lam <- lam+p
          if(object(y)<object(x)+e*t(gradient(x))%*%(y-x))   lam <- lam-p
          y <- x+lam*(theta.tu-x); p <- p/2
        }
        theta.next <- y
      }
      if(max(abs(theta.next-theta.current))<=accuracy) {index=1;iterate=iterate+1; break}
      iterate <- iterate+1
    }
    list(index=index,iterate=iterate-1,theta.est=theta.next)
  }
  
}





##### basis. is a function to compute the ith B-spline basis function evaluated at x(can be a vector),bs1. is to return the B matix with knots and x (x need not be that generating the knots(like bs()),x can be totally unrelated to the knots)

basis. <- function(x, degree, i, knots) {
  if(degree == 0){
    B <- ifelse((x >= knots[i]) & (x < knots[i+1]), 1, 0)
  } else {
    if((knots[degree+i] - knots[i]) == 0) {
      alpha1 <- 0
    } else {
      alpha1 <- (x - knots[i])/(knots[degree+i] - knots[i])
    }
    if((knots[i+degree+1] - knots[i+1]) == 0) {
      alpha2 <- 0
    } else {
      alpha2 <- (knots[i+degree+1] - x)/(knots[i+degree+1] - knots[i+1])
    }
    B <- alpha1*basis.(x, (degree-1), i, knots) + alpha2*basis.(x, (degree-1), (i+1), knots)
  }
  return(B)
}

bs1. <- function(x, degree=3, interior.knots=NULL, intercept=FALSE, Boundary.knots = c(0,1)) {
  if(missing(x)) stop("You must provide x")
  if(degree < 1) stop("The spline degree must be at least 1")
  Boundary.knots <- sort(Boundary.knots)
  interior.knots.sorted <- NULL
  if(!is.null(interior.knots)) interior.knots.sorted <- sort(interior.knots)
  knots <- c(rep(Boundary.knots[1], (degree+1)), interior.knots.sorted, rep(Boundary.knots[2], (degree+1)))
  K <- length(interior.knots) + degree + 1
  B.mat <- matrix(0,length(x),K)
  for(j in 1:K) B.mat[,j] <- basis.(x, degree, j, knots)
  if(any(x == Boundary.knots[2])) B.mat[x == Boundary.knots[2], K] <- 1
  if(intercept == FALSE) {
    return(B.mat[,-1])
  } else {
    return(B.mat)
  }
}





##### penalized spline estimation and regression spline estimation

choose.lambda<-function(nsub,max.obs,irate,len,nknots,nr,theta0,lambda.vector0,lambda.vector1)
{
  theta.est1 <-  theta.est.choose <- rep(0,length(theta0)) 
  splineknot<- list()
  lambda0.best <- lambda1.best <- c()
  D <- diff(diff(diag(nknots+4))) 
  Amat<-matrix(0,length(theta0),length(theta0))
  diag(Amat)<--1
  for(i in 1:(length(theta0)-1)){Amat[i,i+1]<-1}
  Amat<-Amat[-((nknots+4):(length(theta0))),]
  bvec<-rep(0,nknots+3)
  knotmin.max <- 0;knotmax.min <- 10
  
  for (i. in 1:nr)
  {
    set.seed(i.) 
    data.all=data.gen(nsub,max.obs,irate,len)
   
    time<-data.all[,2]
    countmat<-data.all[,3]
    covar1.<-data.all[,4]
    covar2.<-data.all[,5]
    covar3.<-data.all[,6]
    
    splineknots<-unname(quantile(time, seq(0, 1, length=nknots+2))) 
    splineknot[[i.]]<- splineknots
    knotmin.max <- max(knotmin.max, min(splineknots))
    knotmax.min <- min(knotmax.min, max(splineknots))
    
    timebasis=bs(time, df = nknots+4, intercept = TRUE)   #generate a set of B-spline basis function
    B<-as.matrix(timebasis)                            #define cubic spline matrix B
    
    CB<-cbind(B,covar1.*B,covar2.,covar3.)
    
    
    cvl <- matrix(0,nrow=length(lambda.vector0),ncol=length(lambda.vector1))
    theta<-rep(0,length(theta0))
    lf.value <- matrix(0,nrow=length(lambda.vector0),ncol=length(lambda.vector1))
     
    for(i.. in 1:length(lambda.vector0))
    {
      for (j in 1:length(lambda.vector1)) #length(lambda.vector)
      {
        P0 <- as.matrix(bdiag((lambda.vector0[i..])*(t(D)%*%D),(lambda.vector1[j])*(t(D)%*%D),matrix(0,nrow=2,ncol=2)))
        
        #pesudo-likelihood function
        plf<-function(theta){
          sum( c(countmat*(CB%*%theta))-c(exp(CB%*%theta)))-0.5*t(theta)%*%P0%*%theta}
        
        #gradient for pesudo-likelihood function
        grad.theta<-function(theta){
          apply(countmat*CB-CB*c(exp(CB%*%theta)),2,sum)-P0%*%theta}
          
        hessian.plf <-function(theta) {(-t(CB)%*%(CB*c(exp(CB%*%theta))))-P0}
        theta.curr <-projected.NR(theta0,plf,grad.theta,hessian.plf,t(Amat),bvec,1e-10,0.25,500)$theta.est
        
        lf.value[i..,j] <- plf(theta.curr)+0.5*t(theta.curr)%*%P0%*%theta.curr   
        
        H.inverse <- solve(hessian.plf(theta.curr))
        cvl[i..,j] <- lf.value[i..,j]-sum(diag((-H.inverse)%*%(-hessian.plf(theta.curr)-P0)))
        theta<-cbind(theta,theta.curr)
        
      }
    }
    theta <- theta[,-1]
    
    best.index0=(which(cvl == max(cvl), arr.ind = TRUE))[1]
    lambda0.best[i.]<-lambda.vector0[best.index0] 
    best.index1=(which(cvl == max(cvl), arr.ind = TRUE))[2]
    lambda1.best[i.]<-lambda.vector1[best.index1] 
    theta.choose <- theta[,(best.index0-1)*length(lambda.vector1)+best.index1]
    theta1 <-theta[,1]
    
    
    theta.est1 <- cbind(theta.est1,theta1)
    theta.est.choose <- cbind(theta.est.choose,theta.choose)
    
  }
  list(theta.est1=theta.est1,theta.est.choose=theta.est.choose,splineknot=splineknot,knotmin.max=knotmin.max,knotmax.min=knotmax.min,lambda0.best=lambda0.best,lambda1.best=lambda1.best)
}




nsub<-100    ## sample size
max.obs<-6
irate<-0.3
len<-10
#replicates for simulation
nr=500
#knots number for spline
nknots=6
theta0<-c(seq(1,2,length=nknots+4),rep(0.000001,nknots+6))

lambda.vector0 <-c(0,c(exp(seq(-0.5,10,length=9))))
lambda.vector1 <-c(0,c(exp(seq(-0.5,10,length=9))))

result. <- choose.lambda(nsub,max.obs,irate,len,nknots,nr,theta0,lambda.vector0,lambda.vector1)
splineknot1<- result.$splineknot
lambda0.best.vec <-result.$lambda0.best 
lambda1.best.vec <-result.$lambda1.best 
lambda0.best.ave <- mean(lambda0.best.vec)
lambda1.best.ave <- mean(lambda1.best.vec)

theta.est1 <- result.$theta.est1
theta.est1 <- theta.est1[,-1]   ## the coefficients of regression spline estimators

theta.est.choose <- result.$theta.est.choose
theta.est.choose <- theta.est.choose [,-1]  # the coefficients of penalized spline estimators

eta0.est1<-(theta.est1)[(1:(nknots+4)),]            
eta1.est1<-(theta.est1)[((nknots+5):(2*(nknots+4))),]   
eta0.est.choose<-(theta.est.choose)[(1:(nknots+4)),]        
eta1.est.choose<-(theta.est.choose)[((nknots+5):(2*(nknots+4))),]   
knotmin.max. <- result.$knotmin.max
knotmax.min. <- result.$knotmax.min

test.time<-seq(0.43, 9.6, len=200)  ## test time-points, which can also be set to other values 
test.time.by <- (diff(range(test.time)))/199

alpha1.est.mat<-alpha2.est.mat<-matrix(0,nrow=2.,ncol = nr) 
loglambda.est.mat1 <- loglambda.est.mat.choose <- matrix(0,length(test.time),nr)
beta.est.mat1 <- beta.est.mat.choose <- matrix(0,length(test.time),nr) 

alpha1.est.mat[1,]<- (theta.est1)[(2*(nknots+4)+1),]
alpha1.est.mat[2,]<- (theta.est.choose)[(2*(nknots+4)+1),]
alpha2.est.mat[1,]<- (theta.est1)[(2*(nknots+4)+2),]
alpha2.est.mat[2,]<- (theta.est.choose)[(2*(nknots+4)+2),]



for(j. in 1: nr)
{ 
  Bsplinemat1 <- bs1.(test.time,degree = 3,interior.knots=(splineknot1[[j.]])[2:(nknots+1)], intercept=T, Boundary.knots = c((splineknot1[[j.]])[1],(splineknot1[[j.]])[nknots+2]))
  loglambda.est.mat1[,j.]<-Bsplinemat1%*%(eta0.est1[,j.])
  loglambda.est.mat.choose[,j.]<-Bsplinemat1%*%(eta0.est.choose[,j.])
  beta.est.mat1[,j.]<-Bsplinemat1%*%(eta1.est1[,j.])
  beta.est.mat.choose[,j.]<-Bsplinemat1%*%(eta1.est.choose[,j.])
}

lambda.est.mat1 <- exp(loglambda.est.mat1)
lambda.est.mat.choose <- exp(loglambda.est.mat.choose)

bias.alpha1.nopenalty <- mean(alpha1.est.mat[1,])-(-0.5)      ## .nopenalty means regression spline  
sd.alpha1.nopenalty <- sd(alpha1.est.mat[1,])
mse.alpha1.nopenalty <-bias.alpha1.nopenalty^2+sd.alpha1.nopenalty^2
bias.alpha2.nopenalty <- mean(alpha2.est.mat[1,])-(1.5)   
sd.alpha2.nopenalty <- sd(alpha2.est.mat[1,])
mse.alpha2.nopenalty <-bias.alpha2.nopenalty^2+sd.alpha2.nopenalty^2

bias.alpha1.penalty <- mean(alpha1.est.mat[2,])-(-0.5)     ## .penalty means penalized spline    
sd.alpha1.penalty<- sd(alpha1.est.mat[2,])
mse.alpha1.penalty <-bias.alpha1.penalty^2+sd.alpha1.penalty^2
bias.alpha2.penalty <- mean(alpha2.est.mat[2,])-(1.5)   
sd.alpha2.penalty <- sd(alpha2.est.mat[2,])
mse.alpha2.penalty <-bias.alpha2.penalty^2+sd.alpha2.penalty^2



##### compute bias and mse for beta(t) and Lambda_0(t)

bias.beta.t.no<- c();mse.beta.t.no<- c();var.beta.t.no<- c()
bias.lambda.t.no<- c();mse.lambda.t.no <- c();var.lambda.t.no<- c()
bias.beta.t.pe<- c();mse.beta.t.pe<- c();var.beta.t.pe<- c()
bias.lambda.t.pe<- c();mse.lambda.t.pe <- c();var.lambda.t.pe<- c()


for(j in 1:length(test.time))
{
  bias.beta.t.no[j] <- mean(beta.est.mat1[j,])-f.beta(test.time[j])
  var.beta.t.no[j]<- var(beta.est.mat1[j,])
  mse.beta.t.no[j] <- (bias.beta.t.no[j])^2+var.beta.t.no[j]        ## mse of beta(test.time[j])
   bias.lambda.t.no[j]<- mean(lambda.est.mat1[j,])-(f.lambda(test.time[j]))
  var.lambda.t.no[j]<- var(lambda.est.mat1[j,])
  mse.lambda.t.no[j]<-(bias.lambda.t.no[j])^2+var.lambda.t.no[j]
  
  
  bias.beta.t.pe[j] <- mean(beta.est.mat.choose[j,])-f.beta(test.time[j])
  var.beta.t.pe[j]<- var(beta.est.mat.choose[j,])
  mse.beta.t.pe[j] <- (bias.beta.t.pe[j])^2+var.beta.t.pe[j]        ## mse of beta(test.time[j])
   bias.lambda.t.pe[j]<- mean(lambda.est.mat.choose[j,])-(f.lambda(test.time[j]))
  var.lambda.t.pe[j]<- var(lambda.est.mat.choose[j,])
  mse.lambda.t.pe[j]<-(bias.lambda.t.pe[j])^2+var.lambda.t.pe[j]
}



mse.beta.integral.no <- (2*sum(mse.beta.t.no)-mse.beta.t.no[1]-mse.beta.t.no[length(test.time)])*test.time.by*0.5
mse.beta.integral.average.no <- mse.beta.integral.no/(diff(range(test.time)))
mse.lambda.integral.no <- (2*sum(mse.lambda.t.no)-mse.lambda.t.no[1]-mse.lambda.t.no[length(test.time)])*test.time.by*0.5
mse.lambda.integral.average.no <- mse.lambda.integral.no/(diff(range(test.time)))

bias.beta.square.no <- bias.beta.t.no^2
bias.beta.square.integral.no <- (2*sum(bias.beta.square.no)-bias.beta.square.no[1]-bias.beta.square.no[length(test.time)])*test.time.by*0.5
bias.beta.square.integral.average.no <- bias.beta.square.integral.no/(diff(range(test.time)))
bias.lambda.square.no <- bias.lambda.t.no^2
bias.lambda.square.integral.no <- (2*sum(bias.lambda.square.no)-bias.lambda.square.no[1]-bias.lambda.square.no[length(test.time)])*test.time.by*0.5
bias.lambda.square.integral.average.no <- bias.lambda.square.integral.no/(diff(range(test.time)))

var.beta.integral.no <- (2*sum(var.beta.t.no)-var.beta.t.no[1]-var.beta.t.no[length(test.time)])*test.time.by*0.5
var.beta.integral.average.no <- var.beta.integral.no/(diff(range(test.time)))
var.lambda.integral.no <- (2*sum(var.lambda.t.no)-var.lambda.t.no[1]-var.lambda.t.no[length(test.time)])*test.time.by*0.5
var.lambda.integral.average.no <- var.lambda.integral.no/(diff(range(test.time)))


mse.beta.integral.pe <- (2*sum(mse.beta.t.pe)-mse.beta.t.pe[1]-mse.beta.t.pe[length(test.time)])*test.time.by*0.5
mse.beta.integral.average.pe <- mse.beta.integral.pe/(diff(range(test.time)))
mse.lambda.integral.pe <- (2*sum(mse.lambda.t.pe)-mse.lambda.t.pe[1]-mse.lambda.t.pe[length(test.time)])*test.time.by*0.5
mse.lambda.integral.average.pe <- mse.lambda.integral.pe/(diff(range(test.time)))

bias.beta.square.pe <- bias.beta.t.pe^2
bias.beta.square.integral.pe <- (2*sum(bias.beta.square.pe)-bias.beta.square.pe[1]-bias.beta.square.pe[length(test.time)])*test.time.by*0.5
bias.beta.square.integral.average.pe <- bias.beta.square.integral.pe/(diff(range(test.time)))
bias.lambda.square.pe <- bias.lambda.t.pe^2
bias.lambda.square.integral.pe <- (2*sum(bias.lambda.square.pe)-bias.lambda.square.pe[1]-bias.lambda.square.pe[length(test.time)])*test.time.by*0.5
bias.lambda.square.integral.average.pe <- bias.lambda.square.integral.pe/(diff(range(test.time)))
var.beta.integral.pe <- (2*sum(var.beta.t.pe)-var.beta.t.pe[1]-var.beta.t.pe[length(test.time)])*test.time.by*0.5
var.beta.integral.average.pe <- var.beta.integral.pe/(diff(range(test.time)))
var.lambda.integral.pe <- (2*sum(var.lambda.t.pe)-var.lambda.t.pe[1]-var.lambda.t.pe[length(test.time)])*test.time.by*0.5
var.lambda.integral.average.pe <- var.lambda.integral.pe/(diff(range(test.time)))

 

end<-Sys.time()
compute_time <- end-start





##### the output values

v1 <- bias.alpha1.nopenalty;v2 <- sd.alpha1.nopenalty;v3 <- mse.alpha1.nopenalty;
v4<- bias.alpha2.nopenalty;v5 <- sd.alpha2.nopenalty;v6 <- mse.alpha2.nopenalty
v7<- bias.beta.square.integral.average.no;v8<- var.beta.integral.average.no;v9<- mse.beta.integral.average.no;
v10 <- bias.lambda.square.integral.average.no;v11 <- var.lambda.integral.average.no;v12 <- mse.lambda.integral.average.no

v13 <- bias.alpha1.penalty;v14 <- sd.alpha1.penalty;v15 <- mse.alpha1.penalty;
v16 <- bias.alpha2.penalty;v17 <- sd.alpha2.penalty;v18 <- mse.alpha2.penalty
v19 <- bias.beta.square.integral.average.pe;v20 <- var.beta.integral.average.pe;v21 <- mse.beta.integral.average.pe;
v22 <- bias.lambda.square.integral.average.pe;v23 <- var.lambda.integral.average.pe;v24 <- mse.lambda.integral.average.pe



